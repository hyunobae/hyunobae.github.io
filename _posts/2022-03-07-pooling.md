---
title: Pooling에 대한 고찰
author: hyunobae
categories: [Pytorch]
tags: [Pytorch]
published: true
---
# Pooling
이번에는 딥 러닝 모델에서 자주 사용되는 pooling에 대해서 정리하도록 하겠다. Pooling은 컴퓨터비전, 특히 CNN에서 많이 사용되는데 고차원의 feature를 축소하는 용도로 많이 사용이 되고 있다. 크기는 줄이면서 중요한 정보는 강조하는 중요한 역할을 맡고 있다. Pooling에는 여러가지 종류가 있는데 아래에서 하나씩 보도록 하겠다.

## Max pooling & Average pooling
<center><img src=https://user-images.githubusercontent.com/54826050/156974070-099b23c2-bbd3-4248-a624-828f875963fe.png></center><br>

Max pooling은 말 그대로 **최대로 pooling을 수행**하겠다고 이해하면 쉽다. 아래 그림은 maxpooling2D의 예시이다. 2x2 maxpooling은  2x2 크기의 영역에서 max pooling을 수행한다는 의미이다. 본 예시는 stride가 2인 경우이다. *Stride는 보폭인데, 2x2 크기의 사각형이 다음 max pooling을 수행할 때 옆으로 얼마나 움직일 것인지 정하는 파라미터이다.* Max pooling을 수행하면 각 2x2 영역에서 가장 큰 수가 선택되는 것을 확인할 수 있다. 예를 들어, 빨간 영역의 [12, 20, 8, 12]에서 **max pooling을 수행하면 가장 큰 수인 20이 선택되는 것**을 의미한다. <br>
Average pooling의 경우, max pooling과 다르게 특정 영역의 가장 큰 값이 아닌, **평균 값을 계산하여 사용**한다. 예를 들어, [12, 20, 8, 12]에서 average pooling을 수행하면 평균값인 13이 계산되는 것이다. 이외의 부분들은 max pooling과 동일하다.<br>
이러한 pooling을 사용하는 이유는 다음과 같다. - CNN에서 다양한 feature를 추출하여 학습하기 위해 많은 수의 filter를 사용하게 된다. 
- 많은 filter를 사용하면 많은 feature map이 생성되어 파라미터의 수가 굉장히 커진다.
- 이때, pooling 기법을 사용하여 feature map의 크기를 줄여서 파라미터 수를 줄여서 학습에 도움을 준다.

## Global Average pooling

<img width="696" alt="global_average_pooling" src="https://user-images.githubusercontent.com/54826050/156975402-9cd230ad-172f-40c9-af98-a5b85effc69c.png"><br>

Global Average pooling (GAP) 는 앞선 pooling들과는 사용하는 원인이 다르다. 그 전에 documentation을 먼저 보자. Pytorch에서는 [AdaptiveAvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html)라 불리는데 여타 다른 pooling과 비슷하게 input과 output의 channel 갯수는 유지가 되는 것을 확인할 수 있다. 그렇다면 GAP는 언제 사용되는가? <br>
실제 용례를 찾아보면 다른 pooling이 convolution층 이후에 사용되는 것과 다르게 GAP는 dense layer를 없애고, 이를 convolution으로 대체할 때 사용된다. 다시 말해, ***dense layer를 사용하지 않기 위함이라는 말이다.*** GAP를 사용하면 다음과 같은 일이 벌어진다.
- 기존 Fully-connected layer를 사용하지 않을 수 있기 떄문에 계산량에서 엄청난 이득을 얻음
- 각 channel이 가지는 값을 **단일 평균 값**으로 대체하기 때문에 *정보의 손실이 굉장히 큼*
- 그럼에도 성능이 좋음<br>

어떻게 feature map을 단일 평균값으로 치환하는데 성능이 좋을 수 있는지 궁금했다. 


#### Image & source
- https://computersciencewiki.org/index.php/File:MaxpoolSample2.png
- https://alexisbcook.github.io/2017/global-average-pooling-layers-for-object-localization/
- https://www.quora.com/Why-was-global-average-pooling-used-instead-of-a-fully-connected-layer-in-GoogLeNet-and-how-was-it-different