---
title: EDVR - Video Restoration with Enhanced Deformable Convolutional Networks
author: hyunobae
categories: [Paper]
tags: [Paper, VSR]
published: false
use_math: true
---

# 개요
---
본 논문은 NTIRE19 Challenge에서 우승한 VSR 모델이다. VSR 뿐만 아니라 deblurring에도 뛰어난 성능을 보여주었다. Pyramid, Cascading and Deformable (PCD) module과 Temporal and Spatial Attention (TSA) fusion module을 도입하여 VSR 문제를 해결하였다.<br>

## Abstract
---
- NTIRE19 Challenge에서 REDS라는 벤치마크가 소개되었는데, 이 벤치마크는 두가지 측면에서 까다로웠다. (1) 모션이 큰 여러가지 frame을 어떻게 align 할 것인가 (2) 많은 모션과 blur가 포함된 여러 frame을 어떻게 fusion할 것인가 이다. 본 논문은 *Video Restoration framework with Enhanced Deformable convolutions*인 ***EDVR***을 제안한다. 큰 모션을 다루기 위해 Pyramid, Cascading and Deformable (PCD) alignment module과 attention을 spatio/temporal 측면에 적용하기 위해 Temporal and Spatial Attention (TSA) fusion module을 도입하였다. 이로 인해 NRITE19에서 우승하게 되었다.
<br>

## Introduction
---
- 최근에 딥러닝 기반의 video super-resolution (VSR)은 4가지 components로 이루어진 pipeline을 사용한다. 이는 feature extraction, alignment (motion estimation), fusion (motion compensation), reconstruction이다. 보통 문제는 alignment와 fusion에서 발생하는데, 영상에 blur나 물체가 가려지는 현상, 그리고 motion이 큰 경우이다. 

#### Alignment
- 많은 모델이 alignment를 수행할 때 explicitly estimating하는 optical flow를 사용한다. 이는 이웃하는 frame을 estimated motion field로 warp한다. 또 다른 방법으로는 implicitly estimating하는 앞서 리뷰한 DUF의 dynamic filtering이나 deformable convolution을 사용하는 것이다. Flow 기반의 방법은 정확한 flow estimation과 정확한 warping을 수행하는데 어렵고, 시간이 오래 걸리기도 한다. Motion이 큰 경우에는 explicit/implicit 방법 모두 어렵다.

#### Fusion
- 대부분의 모델이 fusion을 convolution을 통해 모든 frame에 대해 early fusion을 수행하거나 recurrent network를 사용하여 점진적으로 fuse하기도 한다. 하지만 현존하는 방법들은 각 frame이 가지는 내재한 시각적인 정보를 고려하지 않는다-각각 다른 frame과 위치는 동등한 정도의 정보 (reconstruction에 도움되는 정보)를 가질 수 없다 (blur나 impefect alignment).

#### Proposing solution
- 위와 같은 문제들을 해결하기 위해, 