---
title: DUF - Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation
author: hyunobae
categories: [Paper]
tags: [Paper, VSR]
published: true
use_math: true
---

# 개요
본 논문은 DUF (Dynamic Upsampling Filters)라고 많이 cite되는 것 같다. 저자는 연세대이고, CVPR 2018에서 발표되었다. 기존 방법과는 다르게 adaptive한 filter를 사용한 것이 굉장히 신선했다. 중요하다고 생각되는 부분만 작성할 예정이라 모든 부분을 다루진 않는다 *(아카이빙 목적이라 고도로 압축 ver..)*. 틀린 부분은 알려주시면 감사하겠습니다.<br>

---

## Abstract
- Video super-resolution (이하 VSR)은 deep learning 기반의 방법을 도입한 후, 많은 방법들이 제안되었지만 많은 방법들은 motion estimation과 compensation의 정확도에 굉장히 의존하였다. 저자들은 dynamic upsampling filters와  residual image를 생성하는 DNN (deep neural net)을 제안하는데, 이는 explicit motion compenmsation (ex. optical flow)을 피하기 위해 각 pixel의 local spatio-temporal neiborhood에 따라 계산된다. 또한, 새로운 data augmentation 기법을 제안한다.
<br><br>
## Introduction
- 전통적인 VSR 알고리즘은 여러개의 LR frame을 input으로 사용하여 subpixel의 motion을 고려하여 HR framne을 output한다. 거의 모든 DNN 기반 알고리즘은 두가지 단계로 구성된다: motion estimation, compensation (+up-sampling). 본 프로세스의 문제점은 결과가 motion estimation의 정확도에 지나치게 의존한다는 것이다
*(motion estimation에서 occlusion이나 blur가 있는 frame이 있다면 성능이 굉장히 떨어지게 되는 것을 의미함)*. 또 발생할 수 있는 다른 문제는 CNN을 통해 motion compensated LR frame들의 mixing vlaue로부터 HR output frame이 생성되는데 이로 인해 blurry된 frame을 얻을 수 있다는 것이다. 

- 따라서, 본 논문에서는 explicit motion compensation 방법을 사용하지 않고, motion information을 implicit하게 활용하여 dynamic upsampling filter (DUF)를 생성한다. 이를 통해 local filtering으로 HR frame을  바로 생성하는 방법을 사용하였다.  
<br><br>  

## Method

### - Dynamic Upsampling Filter
<center><img src='https://user-images.githubusercontent.com/54826050/136738285-ea5ef9a0-7043-42f9-9a43-1892a75271ae.PNG'></center><br>

- 기존 upsampling filter의 값은 고정된 값이기 때문에 부자연스러운 결과가 생성된다 (bilinear, bicubic, ..). 저자들은 LR frames의 각 픽셀의 spatio-temporal한 neighborhood에 기반한 upsampling filter인 DUF를 제안하였다.

- 위 그림은 DUF를 통해 upsampling하는 것을 보여준다. Input frames로 dynamic filter generation network으로 학습하여 $r^2HW$의 set을 가지는 upsampling filter $F_t$를 생성한다. 이때, filter의 size는 특정하기 나름이다 (예시는 5x5). 
- 첨부한 그림은 *x4 upsampling*의 예시인데, input frames 중 center frame인 $X_t$의 (3,3)을 upsampling한다고 가정하자. 이때는 x4 upsampling이기 때문에 ***1개의 픽셀 당 16개의 upsampling filter가 사용된다.*** HR frame에 상응하는 좌표인 (3,3) -> (12,12)에서 16개의 새로운 픽셀이 생성되는 것을 확인할 수 있다.

- 위 과정을 수식을 통해 정리한다면 다음과 같다. 

$$\bar{Y}_t(yr+v, xr+u) = \sum_{j=-2}^{2} \sum_{i=-2}^{2} F^{x,y,v,u}_t(j+2, i+2) X_t(y+j,x+i)$$


이때, x,y는 LR frame의 좌표이고 u,v는 $r$ x $r$ block의 좌표이다
( 0 $\le$ $v,u$ $\le$ $r$-1 ). 예를 들어, r=4인 경우에는 0부터 3이 v,u의 값이 된다.

- DUF가 기존과 다른 점은 기존의 DL 기반 모델은 feature space에서 여러개의 convolution을 통해 HR frame을 reconstruct하는 방법을 학습하지만, 본 논문에서는 ***가장 좋은 upsampling filters를 학습하기 위해 DL을 사용한다.***
<br>

### - Residual Learning
- 기존의 방법은 LR frame을 bicubically upsampled된 image에 residual을 더해주어 output HR frame을 생성하였다. 

- 본 논문에서는 여러 개의 input frames로부터 residual image를 생성하고, ***DUF를 적용하여 upsampled된 frame에 residual을 더하여 좀 더  spatial shaprness와 temporal consistency가 보장된 HR frame을 생성한다.*** 
<br>
<br>

## Network Design

<center><img src='https://user-images.githubusercontent.com/54826050/136779762-5b6164ce-bd02-44c8-a4f5-945eaf2b9a88.png'></center><br>

- 본 그림은 네트워크의 전체 구조이다. 결과적으로 residual image와 DUF 2개를 생성하기 때문에 network의 overhead를 줄이기 위해 weight sharing을 적용하였다. 

- Network는 *Dense block*을 참고하여 구성하였는데, 내부의 2D convolutional layer를 **3D convolutional layer**로 변경하여 spatio-temporal features를 학습하도록 하였다. 이는 spatio-temporal feature extraction을 수행하기 위함이다.  

- 본 네트워크를 살펴보면 BN (Batch-Normalization)이 적용되는데, SR task에서는 BN이 오히려 feature의 특성을 없애는 경향이 있어서 사용하지 않는다고 알고 있었는데 적용한 것이 독특했다 *(개인적인 생각. 반박 대환영입니다)*. 

- 앞서 설명한 것과 같이, <br>1) input frames로 부터 DUF를 생성하기 위해 학습하고<br>2) 생성된 DUF로 center frame에 SR을 수행한 후<br> 3) residual이 더해져서  최종 output frame이 생성되는 것을 확인할 수 있다.
<br><br>

## Temporal Augmentation
<center><img src="https://user-images.githubusercontent.com/54826050/136781692-04636007-c467-4e46-adce-a2f0d7a9c8c7.png"></center>
<br>

- 본 그림은 새롭게 적용한 data augmentation의 예시이다. 기존의 방법은 rotation이나 flip을 통해 data를 생성하였다.

- 저자들은 *sampling interval*을 도입하여 temporal augmentation을 적용하였다. 예를 들어, TA가 2인 경우는 t, t+2, ..와 같이 frame의 간격을 2로 두고 forward direction으로 sampling을 하여 motion의 측면에서 더 빠른 것 처럼 data를 사용할 수 있다는 것이다. - 값을 주면 backward direction으로 sampling을 수행하여 좀 더 ***motion에 있어서 다양한 data를 만들 수 있는 방법***이다.

<br><br>

## Implementation
### Datasets
- 351개의 video dataset에서 160,000개의 144 x 144 GT training data 구성
- Derf's collection에서 coastguard, foreman, gatden, husky valset으로 사용
<br>
### Training
- GT data에 Gaussian filter로 smoothing 수행 후, sub-sampling 수행
- Input patch는 32x32, 16 batch size
- Huber loss 사용
- Test phase에서 temporal axis로 zero padding 수행 (프레임 수 유지를 위해)

<br><br>


## Experimental Result
<center><img src="https://user-images.githubusercontent.com/54826050/136784457-1f386d9f-58ed-40a5-a808-88014644e457.png"></center>

- 표는 PSNR과 SSIM을 정리한 것이다. 여기서 16L, 28L, 52L은 newwork의 layer 수를 의미한다. 역시 기존의 통념과 같이, layer가 깊어질수록 성능이 올라가는 것을 확인할 수 있다. 특히, 선이 촘촘하게 구성된 frame에 대해서 더 좋은 성능을 보이기도 하였다. <br>

<center><img src="https://user-images.githubusercontent.com/54826050/136784913-d0449dd9-3341-4a09-acc3-3d249df9a023.png"></center>

- DUF가 다른 제안된 예시보다 복잡한 문양이나 detail한 부분들을 더 잘 복원하는 것을 보여준다. 특히, 제안된 기법에서 layer가 깊은 경우, 처마와 같이 촘촘한 부분에서 강한 모습을 보여주었다.


<br><br>

## Conclusion
- 본 논문에서는 dynamic upsampling filter와 residual image를 생성하여 VSR 문제를 해결하였다.
- 특히, explicit motion estimation을 적용하지 않고 motion을 handle하는 방법을 사용하였다. 

























