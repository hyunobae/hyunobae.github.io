<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="DUF - Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation" /><meta name="author" content="hyunobae" /><meta property="og:locale" content="en" /><meta name="description" content="개요 본 논문은 DUF (Dynamic Upsampling Filters)라고 많이 cite되는 것 같다. 저자는 연세대이고, CVPR 2018에서 발표되었다. 기존 방법과는 다르게 adaptive한 filter를 사용한 것이 굉장히 신선했다. 중요하다고 생각되는 부분만 작성할 예정이라 모든 부분을 다루진 않는다 (아카이빙 목적이라 고도로 압축 ver..). 틀린 부분은 알려주시면 감사하겠습니다." /><meta property="og:description" content="개요 본 논문은 DUF (Dynamic Upsampling Filters)라고 많이 cite되는 것 같다. 저자는 연세대이고, CVPR 2018에서 발표되었다. 기존 방법과는 다르게 adaptive한 filter를 사용한 것이 굉장히 신선했다. 중요하다고 생각되는 부분만 작성할 예정이라 모든 부분을 다루진 않는다 (아카이빙 목적이라 고도로 압축 ver..). 틀린 부분은 알려주시면 감사하겠습니다." /><link rel="canonical" href="https://hyunobae.github.io/posts/DUF/" /><meta property="og:url" content="https://hyunobae.github.io/posts/DUF/" /><meta property="og:site_name" content="Hyuno’s Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-10-11T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="DUF - Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@hyunobae" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"hyunobae"},"description":"개요 본 논문은 DUF (Dynamic Upsampling Filters)라고 많이 cite되는 것 같다. 저자는 연세대이고, CVPR 2018에서 발표되었다. 기존 방법과는 다르게 adaptive한 filter를 사용한 것이 굉장히 신선했다. 중요하다고 생각되는 부분만 작성할 예정이라 모든 부분을 다루진 않는다 (아카이빙 목적이라 고도로 압축 ver..). 틀린 부분은 알려주시면 감사하겠습니다.","url":"https://hyunobae.github.io/posts/DUF/","headline":"DUF - Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation","dateModified":"2021-10-11T23:13:43+08:00","datePublished":"2021-10-11T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://hyunobae.github.io/posts/DUF/"},"@type":"BlogPosting","@context":"https://schema.org"}</script><title>DUF - Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation | Hyuno's Blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Hyuno's Blog"><meta name="application-name" content="Hyuno's Blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } }, tex2jax: { inlineMath: [ ['$', '$'] ], displayMath: [ ['$$', '$$'] ], processEscapes: true } }); MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) { alert("Math Processing Error: "+message[1]); }); MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) { alert("Math Processing Error: "+message[1]); }); </script> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://res.cloudinary.com/knu/image/upload/v1633838508/me_ft64be.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Hyuno's Blog</a></div><div class="site-subtitle font-italic">M.S. student at Kyungpook National University</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/hyunobae" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['jayangie','knu.ac.kr'].join('@')" aria-label="email" class="order-4" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-5" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>DUF - Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>DUF - Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> hyunobae </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Oct 11, 2021, 12:00 AM +0800" >Oct 11, 2021<i class="unloaded">2021-10-11T00:00:00+08:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Tue, Oct 12, 2021, 12:13 AM +0900" >Oct 12, 2021<i class="unloaded">2021-10-11T23:13:43+08:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1728 words">9 min read</span></div></div><div class="post-content"><h1 id="개요">개요</h1><hr /><p>본 논문은 DUF (Dynamic Upsampling Filters)라고 많이 cite되는 것 같다. 저자는 연세대이고, CVPR 2018에서 발표되었다. 기존 방법과는 다르게 adaptive한 filter를 사용한 것이 굉장히 신선했다. 중요하다고 생각되는 부분만 작성할 예정이라 모든 부분을 다루진 않는다 <em>(아카이빙 목적이라 고도로 압축 ver..)</em>. 틀린 부분은 알려주시면 감사하겠습니다.<br /></p><h2 id="abstract">Abstract</h2><hr /><ul><li>Video super-resolution (이하 VSR)은 deep learning 기반의 방법을 도입한 후, 많은 방법들이 제안되었지만 많은 방법들은 motion estimation과 compensation의 정확도에 굉장히 의존하였다. 저자들은 dynamic upsampling filters와 residual image를 생성하는 DNN (deep neural net)을 제안하는데, 이는 explicit motion compenmsation (ex. optical flow)을 피하기 위해 각 pixel의 local spatio-temporal neiborhood에 따라 계산된다. 또한, 새로운 data augmentation 기법을 제안한다. <br /><br /></ul><h2 id="introduction">Introduction</h2><hr /><ul><li><p>전통적인 VSR 알고리즘은 여러개의 LR frame을 input으로 사용하여 subpixel의 motion을 고려하여 HR framne을 output한다. 거의 모든 DNN 기반 알고리즘은 두가지 단계로 구성된다: motion estimation, compensation (+up-sampling). 본 프로세스의 문제점은 결과가 motion estimation의 정확도에 지나치게 의존한다는 것이다 <em>(motion estimation에서 occlusion이나 blur가 있는 frame이 있다면 성능이 굉장히 떨어지게 되는 것을 의미함)</em>. 또 발생할 수 있는 다른 문제는 CNN을 통해 motion compensated LR frame들의 mixing vlaue로부터 HR output frame이 생성되는데 이로 인해 blurry된 frame을 얻을 수 있다는 것이다.</p><li><p>따라서, 본 논문에서는 explicit motion compensation 방법을 사용하지 않고, motion information을 implicit하게 활용하여 dynamic upsampling filter (DUF)를 생성한다. 이를 통해 local filtering으로 HR frame을 바로 생성하는 방법을 사용하였다.<br /> <br /><br /></p></ul><h2 id="method">Method</h2><hr /><h3 id="--dynamic-upsampling-filter">- Dynamic Upsampling Filter</h3><center><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/54826050/136738285-ea5ef9a0-7043-42f9-9a43-1892a75271ae.PNG" /></center><p><br /></p><ul><li><p>기존 upsampling filter의 값은 고정된 값이기 때문에 부자연스러운 결과가 생성된다 (bilinear, bicubic, ..). 저자들은 LR frames의 각 픽셀의 spatio-temporal한 neighborhood에 기반한 upsampling filter인 DUF를 제안하였다.</p><li>위 그림은 DUF를 통해 upsampling하는 것을 보여준다. Input frames로 dynamic filter generation network으로 학습하여 $r^2HW$의 set을 가지는 upsampling filter $F_t$를 생성한다. 이때, filter의 size는 특정하기 나름이다 (예시는 5x5).<li><p>첨부한 그림은 <em>x4 upsampling</em>의 예시인데, input frames 중 center frame인 $X_t$의 (3,3)을 upsampling한다고 가정하자. 이때는 x4 upsampling이기 때문에 <strong><em>1개의 픽셀 당 16개의 upsampling filter가 사용된다.</em></strong> HR frame ($\bar{Y}_t$)에 상응하는 좌표인 (3,3) -&gt; (12,12)에서 16개의 새로운 픽셀이 생성되는 것을 확인할 수 있다.</p><li>위 과정을 수식을 통해 정리한다면 다음과 같다.</ul><p>$ \bar{Y}_t(yr+v, xr+u)=\sum_{j=-2}^{2}\sum_{i=-2}^{2}F^{x,y,v,u}_t(j+2, i+2)X_t(y+j, x+i) $</p><p>이때, x,y는 LR frame의 좌표이고 u,v는 $r$ x $r$ block의 좌표이다 ( 0 $\le$ $v,u$ $\le$ $r$-1 ). 예를 들어, r=4인 경우에는 0부터 3이 v,u의 값이 된다.</p><ul><li>DUF가 기존과 다른 점은 기존의 DL 기반 모델은 feature space에서 여러개의 convolution을 통해 HR frame을 reconstruct하는 방법을 학습하지만, 본 논문에서는 <strong><em>가장 좋은 upsampling filters를 학습하기 위해 DL을 사용한다.</em></strong> <br /></ul><h3 id="--residual-learning">- Residual Learning</h3><ul><li><p>기존의 방법은 LR frame을 bicubically upsampled된 image에 residual을 더해주어 output HR frame을 생성하였다.</p><li><p>본 논문에서는 여러 개의 input frames로부터 residual image를 생성하고, <strong><em>DUF를 적용하여 upsampled된 frame에 residual을 더하여 좀 더 spatial shaprness와 temporal consistency가 보장된 HR frame을 생성한다.</em></strong> <br /> <br /></p></ul><h2 id="network-design">Network Design</h2><hr /> <center><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/54826050/136779762-5b6164ce-bd02-44c8-a4f5-945eaf2b9a88.png" /></center><p><br /></p><ul><li><p>본 그림은 네트워크의 전체 구조이다. 결과적으로 residual image와 DUF 2개를 생성하기 때문에 network의 overhead를 줄이기 위해 weight sharing을 적용하였다.</p><li><p>Network는 <em>Dense block</em>을 참고하여 구성하였는데, 내부의 2D convolutional layer를 <strong>3D convolutional layer</strong>로 변경하여 spatio-temporal features를 학습하도록 하였다. 이는 spatio-temporal feature extraction을 수행하기 위함이다.</p><li><p>본 네트워크를 살펴보면 BN (Batch-Normalization)이 적용되는데, SR task에서는 BN이 오히려 feature의 특성을 없애는 경향이 있어서 사용하지 않는다고 알고 있었는데 적용한 것이 독특했다 <em>(개인적인 생각. 반박 대환영입니다)</em>.</p><li><p>앞서 설명한 것과 같이, <br />1) input frames로 부터 DUF를 생성하기 위해 학습하고<br />2) 생성된 DUF로 center frame에 SR을 수행한 후<br /> 3) residual이 더해져서 최종 output frame이 생성되는 것을 확인할 수 있다. <br /><br /></p></ul><h2 id="temporal-augmentation">Temporal Augmentation</h2><hr /> <center><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/54826050/136781692-04636007-c467-4e46-adce-a2f0d7a9c8c7.png" /></center><p><br /></p><ul><li><p>본 그림은 새롭게 적용한 data augmentation의 예시이다. 기존의 방법은 rotation이나 flip을 통해 data를 생성하였다.</p><li><p>저자들은 <em>sampling interval</em>을 도입하여 temporal augmentation을 적용하였다. 예를 들어, TA가 2인 경우는 t, t+2, ..와 같이 frame의 간격을 2로 두고 forward direction으로 sampling을 하여 motion의 측면에서 더 빠른 것 처럼 data를 사용할 수 있다는 것이다. - 값을 주면 backward direction으로 sampling을 수행하여 좀 더 <strong><em>motion에 있어서 다양한 data를 만들 수 있는 방법</em></strong>이다.</p></ul><p><br /><br /></p><h2 id="implementation">Implementation</h2><hr /><h3 id="datasets">Datasets</h3><ul><li>351개의 video dataset에서 160,000개의 144 x 144 GT training data 구성<li>Derf’s collection에서 coastguard, foreman, gatden, husky valset으로 사용 <br /><h3 id="training">Training</h3><li>GT data에 Gaussian filter로 smoothing 수행 후, sub-sampling 수행<li>Input patch는 32x32, 16 batch size<li>Huber loss 사용<li>Test phase에서 temporal axis로 zero padding 수행 (프레임 수 유지를 위해)</ul><p><br /><br /></p><h2 id="experimental-result">Experimental Result</h2><hr /> <center><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/54826050/136784457-1f386d9f-58ed-40a5-a808-88014644e457.png" /></center><ul><li>표는 PSNR과 SSIM을 정리한 것이다. 여기서 16L, 28L, 52L은 newwork의 layer 수를 의미한다. 역시 기존의 통념과 같이, layer가 깊어질수록 성능이 올라가는 것을 확인할 수 있다. 특히, 선이 촘촘하게 구성된 frame에 대해서 더 좋은 성능을 보이기도 하였다. <br /></ul><center><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/54826050/136784913-d0449dd9-3341-4a09-acc3-3d249df9a023.png" /></center><ul><li>DUF가 다른 제안된 예시보다 복잡한 문양이나 detail한 부분들을 더 잘 복원하는 것을 보여준다. 특히, 제안된 기법에서 layer가 깊은 경우, 처마와 같이 촘촘한 부분에서 강한 모습을 보여주었다.</ul><p><br /><br /></p><h2 id="conclusion">Conclusion</h2><hr /><ul><li>본 논문에서는 dynamic upsampling filter와 residual image를 생성하여 VSR 문제를 해결하였다.<li>특히, explicit motion estimation을 적용하지 않고 motion을 handle하는 방법을 사용하였다. <br /><br /></ul><h2 id="reference">Reference</h2><hr /><p><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers_backup/Jo_Deep_Video_Super-Resolution_CVPR_2018_paper.pdf">Deep Video Super-Resolution Networking Using Dynamic Upsampling Filters Without Explicit Motion Compensation</a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/paper/'>Paper</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/paper/" class="post-tag no-text-decoration" >Paper</a> <a href="/tags/vsr/" class="post-tag no-text-decoration" >VSR</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://www.facebook.com/sharer/sharer.php?title=DUF - Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation - Hyuno's Blog&u=https://hyunobae.github.io/posts/DUF/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=DUF - Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation - Hyuno's Blog&url=https://hyunobae.github.io/posts/DUF/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/deque/">기능개발 (Python)</a><li><a href="/posts/heapq/">더 맵게 (Python)</a><li><a href="/posts/pooling/">Pooling에 대한 고찰</a><li><a href="/posts/pytorch_train/">zero_grad(), step(), 그리고 backward()에 대한 고찰</a><li><a href="/posts/pytorch_dataloader/">Dataloader란?</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/algorithm/">algorithm</a> <a class="post-tag" href="/tags/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4/">프로그래머스</a> <a class="post-tag" href="/tags/pytorch/">Pytorch</a> <a class="post-tag" href="/tags/deque/">deque</a> <a class="post-tag" href="/tags/paper/">Paper</a> <a class="post-tag" href="/tags/combinations/">combinations</a> <a class="post-tag" href="/tags/heap/">heap</a> <a class="post-tag" href="/tags/vsr/">VSR</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/paper-list/"><div class="card-body"> <span class="timeago small" >Oct 10, 2021<i class="unloaded">2021-10-10T00:00:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>리뷰할 논문 리스트</h3><div class="text-muted small"><p> 개요 현재 연구하고 있는 분야가 super-resolution (SR)이다. 특히, 이미지 SR이 아닌, video를 SR하는 Video SR (이하 VSR)과 관련된 연구를 진행하고 있다. 따라서, 서로 다른 몇 편의 VSR 논문을 리뷰할 예정이다. 리뷰할 논문의 리스트는 다음과 같다. 리뷰할 논문 리스트 VSRnet - Video Super...</p></div></div></a></div><div class="card"> <a href="/posts/make_primenum/"><div class="card-body"> <span class="timeago small" >May 17<i class="unloaded">2022-05-17T00:00:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>소수만들기 (Python)</h3><div class="text-muted small"><p> 문제 설명 주어진 숫자 중 3개의 수를 더했을 때 소수가 되는 경우의 개수를 구하려고 합니다. 숫자들이 들어있는 배열 nums가 매개변수로 주어질 때, nums에 있는 숫자들 중 서로 다른 3개를 골라 더했을 때 소수가 되는 경우의 개수를 return 하도록 solution 함수를 완성해주세요. 제한 사항 nums에 들어있는 숫자의 개수는 3개 ...</p></div></div></a></div><div class="card"> <a href="/posts/printer/"><div class="card-body"> <span class="timeago small" >May 10<i class="unloaded">2022-05-10T00:00:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>프린터 (Python)</h3><div class="text-muted small"><p> 문제 설명 일반적인 프린터는 인쇄 요청이 들어온 순서대로 인쇄합니다. 그렇기 때문에 중요한 문서가 나중에 인쇄될 수 있습니다. 이런 문제를 보완하기 위해 중요도가 높은 문서를 먼저 인쇄하는 프린터를 개발했습니다. 이 새롭게 개발한 프린터는 아래와 같은 방식으로 인쇄 작업을 수행합니다. 인쇄 대기목록의 가장 앞에 있는 문서(J)를 대기목...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/paper-list/" class="btn btn-outline-primary" prompt="Older"><p>리뷰할 논문 리스트</p></a> <a href="/posts/pytorch_train/" class="btn btn-outline-primary" prompt="Newer"><p>zero_grad(), step(), 그리고 backward()에 대한 고찰</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/hyunobae">hyunobae</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/algorithm/">algorithm</a> <a class="post-tag" href="/tags/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4/">프로그래머스</a> <a class="post-tag" href="/tags/pytorch/">Pytorch</a> <a class="post-tag" href="/tags/deque/">deque</a> <a class="post-tag" href="/tags/paper/">Paper</a> <a class="post-tag" href="/tags/combinations/">combinations</a> <a class="post-tag" href="/tags/heap/">heap</a> <a class="post-tag" href="/tags/vsr/">VSR</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://hyunobae.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"> </script>
